{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_3O3luoQxk7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4afe77f6-56e9-4d82-c320-6ff66aa0cb8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "bDUhzwfYxry3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using English Dataset"
      ],
      "metadata": {
        "id": "kWA-aNu2BD7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_dataset = pd.read_csv('/content/drive/MyDrive/Data Augmentation/data/en-dataset.csv', encoding='latin-1', names=[\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"])"
      ],
      "metadata": {
        "id": "_-3rSGaQBFgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_dataset.drop([\"id\", \"date\", \"flag\", \"user\"], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "V_ss6YgHDCeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_tweets = pd.DataFrame()\n",
        "selected_tweets['content'] = []\n",
        "selected_tweets['feeling'] = []\n",
        "\n",
        "selected_tweets"
      ],
      "metadata": {
        "id": "M8g0uiUZBrL0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "039c93ec-a9c2-4c62-f668-eb384be5434d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [content, feeling]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1629e730-1779-4731-80e2-bfed265d1871\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>feeling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1629e730-1779-4731-80e2-bfed265d1871')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1629e730-1779-4731-80e2-bfed265d1871 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1629e730-1779-4731-80e2-bfed265d1871');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_dataset = english_dataset.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "Hofzn174Da9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cdMlWrEhEbuy",
        "outputId": "8e499ded-118a-4c71-e24d-1e65b1a8df44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         target                                               text\n",
              "0             0                          Bed. TIFA meeting at 8am \n",
              "1             0  Day 2: Now in cali. [...] its raining though.....\n",
              "2             4  Over at a friends house, chilaxing and making ...\n",
              "3             0  ugh softball tonight and I do nooot feel good ...\n",
              "4             4                        @laurathe 'Course they win \n",
              "...         ...                                                ...\n",
              "1599995       4  @archetypo if I could play Scrabble on Twitter...\n",
              "1599996       4  @Destini41 Morning Destini, Have a safe trip t...\n",
              "1599997       0  Wishing I didn't live so far away from all the...\n",
              "1599998       0                               not feeling well... \n",
              "1599999       4  LEANNE is back to the world of INTERNET.. welc...\n",
              "\n",
              "[1600000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2f232f3-4a82-4467-ad26-74f31040d6db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Bed. TIFA meeting at 8am</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Day 2: Now in cali. [...] its raining though.....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Over at a friends house, chilaxing and making ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>ugh softball tonight and I do nooot feel good ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>@laurathe 'Course they win</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599995</th>\n",
              "      <td>4</td>\n",
              "      <td>@archetypo if I could play Scrabble on Twitter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599996</th>\n",
              "      <td>4</td>\n",
              "      <td>@Destini41 Morning Destini, Have a safe trip t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599997</th>\n",
              "      <td>0</td>\n",
              "      <td>Wishing I didn't live so far away from all the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599998</th>\n",
              "      <td>0</td>\n",
              "      <td>not feeling well...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599999</th>\n",
              "      <td>4</td>\n",
              "      <td>LEANNE is back to the world of INTERNET.. welc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1600000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2f232f3-4a82-4467-ad26-74f31040d6db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2f232f3-4a82-4467-ad26-74f31040d6db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2f232f3-4a82-4467-ad26-74f31040d6db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_tweets = 0\n",
        "for x, y in enumerate(english_dataset['text']):\n",
        "  if number_of_tweets < 50:\n",
        "    try:\n",
        "      print(y)\n",
        "      number_of_tweets += 1\n",
        "      print(number_of_tweets)\n",
        "      selected_tweets = selected_tweets.append({'content' : str(y), 'feeling': str(english_dataset['target'][x])}, ignore_index=True)\n",
        "      print('adicionou')\n",
        "    except:\n",
        "      print('error')  \n",
        "  else: \n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji8bmZhKD-Z2",
        "outputId": "1e03fff4-83fb-41e7-d314-332018e3ee64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to go to Africa to play with MY elephants so badly.  In the meantime I guess I'll just watch NEMO!\n",
            "1\n",
            "adicionou\n",
            "@imcute519 hehehe  my mom used to get pissed off because i would sing what's my age again to my grandparents lololol\n",
            "2\n",
            "adicionou\n",
            "@tindallafla  I actually wanted a daughter too....most dudes aint to excited bout having a girl...im on cloud 9 lol\n",
            "3\n",
            "adicionou\n",
            "HI. back soon \n",
            "4\n",
            "adicionou\n",
            "my house got cleaned today.. all my stuff got moved around and half of my vicks vapors are gone \n",
            "5\n",
            "adicionou\n",
            " This mood is more shittysweet then bitter. At least it's FINALLY gettin fixed. UGH.\n",
            "6\n",
            "adicionou\n",
            "is in college   and wants to go home and see her bezzie as she has jus returned from turkey  x\n",
            "7\n",
            "adicionou\n",
            "@AnikaRamirez seriously....that was great stuff....now I am sad \n",
            "8\n",
            "adicionou\n",
            "I'm on my 600th Tweet!! Woo Hoo!! \n",
            "9\n",
            "adicionou\n",
            "Yay diversity  I think it's quite sad how I got *so* sucked into the program.. haha still, I enjoyed it. And diversity deserved to win!\n",
            "10\n",
            "adicionou\n",
            "@goldswallow very very little, for money is a little tight this month sadly \n",
            "11\n",
            "adicionou\n",
            "Mmmmm who doesent lik laying by the pool on a hot day \n",
            "12\n",
            "adicionou\n",
            "@jess1283: you always look good baby! yeah, gonna try to have fun... \n",
            "13\n",
            "adicionou\n",
            "Fell asleep in his jeans last night... \n",
            "14\n",
            "adicionou\n",
            "FTSK concert May 23?!  I'm think Soooo!  \n",
            "15\n",
            "adicionou\n",
            "oh btw, the gway you're following is a fakie. twitter.com/gerardway is the real deal \n",
            "16\n",
            "adicionou\n",
            "Racheyy just fixed the laptop and is now going home \n",
            "17\n",
            "adicionou\n",
            "im only going to be gone for 2 weeks. and i promise ill text \n",
            "18\n",
            "adicionou\n",
            "lost my appetite that i dont even feel like finishing my chipotle.. that says alot \n",
            "19\n",
            "adicionou\n",
            "@tacce God that's gotta be scary.  In mid day too. WTF CALIFORNIAN ROBBERS\n",
            "20\n",
            "adicionou\n",
            "it pays to do your research! i had an interview for a SCAM tonight, so glad i didn't make that mistake! i called them &amp; said FUCK YOU! \n",
            "21\n",
            "adicionou\n",
            "@babygirlparis  no f/u from my many tweets to you\n",
            "22\n",
            "adicionou\n",
            "headed to the airport. going to miss the fam  but had so much fun!\n",
            "23\n",
            "adicionou\n",
            "@shavannarene no I wasn't a bridezilla...I should of been though! I planned the wedding all by myself \n",
            "24\n",
            "adicionou\n",
            "Happy Father's Day everyone. I miss you daddy... \n",
            "25\n",
            "adicionou\n",
            "MORNING!!!!!  Another B-E-A-U-tiful day!!!\n",
            "26\n",
            "adicionou\n",
            "@Tatterededges Noooooo. Boo for computer problems. I can empathise. \n",
            "27\n",
            "adicionou\n",
            "Rufus Thomas just came on my iPod random shuffle sad  ill never forget the sequin shorts an shirt sets though!\n",
            "28\n",
            "adicionou\n",
            "Hopefully my group's play get selected. I might consider acting in the future...  cross your fingers. It ain't easy making it big!\n",
            "29\n",
            "adicionou\n",
            "@bryankannowski Sweet.  Just let me know if you have anything you would like to try!\n",
            "30\n",
            "adicionou\n",
            "Chillin at the house with Larry, Jen, Tommy, and Frank.  They are drinking I'm not...  \n",
            "31\n",
            "adicionou\n",
            "YO updating  www.TVyo.nl\n",
            "32\n",
            "adicionou\n",
            "@MariahUKFan lol ok man you sleep ALOT! Lol ya im good so happy that maddie and me got to talk but a little worried for queen  shes sad\n",
            "33\n",
            "adicionou\n",
            "Ive been ignoring Twitter tonight ...I feel bad about it \n",
            "34\n",
            "adicionou\n",
            "@Jonasbrothers yeah, don't say &quot;all&quot; you're not coming to Portugal \n",
            "35\n",
            "adicionou\n",
            " Goood Morning Twittz. I'm in an Extremely good mood. Heading to the GYM with my doll Nessa.\n",
            "36\n",
            "adicionou\n",
            "Is annoyed the queue for the new milkshake place is massive  sad times and hopes the sims 3 will work on my mac!\n",
            "37\n",
            "adicionou\n",
            "@iViva i would love to see Ant and Dec doing a dance with Stavros Flatley! I would cry laughing! They should do it \n",
            "38\n",
            "adicionou\n",
            "feeling very lonely.............. \n",
            "39\n",
            "adicionou\n",
            "@DestinySports  which one do you think i am?\n",
            "40\n",
            "adicionou\n",
            "oh toy story 3 is going to be great \n",
            "41\n",
            "adicionou\n",
            "@ipathia I totally adore cats, I have 2 males and a female. We recently lost our kitten female. She disappeared (7wks now) \n",
            "42\n",
            "adicionou\n",
            "@tommcfly hi tom ! now you'll say: hi fer, please it's not difficul , please honey \n",
            "43\n",
            "adicionou\n",
            "2:30 ... i am done with pre-calc benchmark .. veryy proudd of ittt \n",
            "44\n",
            "adicionou\n",
            "mmm. alone in the atmosphere. \n",
            "45\n",
            "adicionou\n",
            "omg!!! victor kim replied to me. yes. THE victor kim. \n",
            "46\n",
            "adicionou\n",
            "@yeahtucker i wish i was a dancer.  \n",
            "47\n",
            "adicionou\n",
            "gonna stop telling you about my pokemon going up levels cos it's HAPPENING SO QUICKLY oh yeah, it's the one game i pwn at \n",
            "48\n",
            "adicionou\n",
            "have a half cup of coffee  yawnn..\n",
            "49\n",
            "adicionou\n",
            "Summer. Little league. I'm one beer short of happy. My Twitter haiku. \n",
            "50\n",
            "adicionou\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def cleaner(tweet):\n",
        "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) \n",
        "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) \n",
        "    tweet = \" \".join(tweet.split())\n",
        "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") \n",
        "    return tweet\n",
        "\n",
        "selected_tweets['content'] = selected_tweets['content'].map(lambda x: cleaner(x))\n",
        "selected_tweets.to_csv('/content/drive/MyDrive/Data Augmentation/data/en-selectedTweets_clean.csv') "
      ],
      "metadata": {
        "id": "RPXKIhQYEDuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_tweets['feeling'] = selected_tweets['feeling'].replace(['0', '2', '4'], ['negative', 'neutral', 'positive'], regex= True)"
      ],
      "metadata": {
        "id": "1tE_olNZFLb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_tweets.to_csv('/content/drive/MyDrive/Data Augmentation/data/en-selectedTweets_clean_labeled.csv')"
      ],
      "metadata": {
        "id": "WI0vYCGdKPQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_tweets = pd.read_csv('/content/drive/MyDrive/Data Augmentation/data/en-selectedTweets_clean_labeled.csv')"
      ],
      "metadata": {
        "id": "ZeNBjMO-Lr-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_tweets_1 = selected_tweets.iloc[0:18, :]"
      ],
      "metadata": {
        "id": "LlF1DV14FLLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_tweets_2 = selected_tweets.iloc[18:36, :]"
      ],
      "metadata": {
        "id": "6AW0HrLEF3aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_tweets_3 = selected_tweets.iloc[36:50, :]"
      ],
      "metadata": {
        "id": "YX4KDf0JGGw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common Ways to Text Data Augmentation"
      ],
      "metadata": {
        "id": "lY0MKNbRMO2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.23.1\n",
        "!pip install scipy==1.5.4\n",
        "!pip install nltk \n",
        "!pip install --upgrade gensim\n",
        "!pip install textblob \n",
        "!pip install googletrans "
      ],
      "metadata": {
        "id": "AtcyOewIsEaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "id": "orWSGgx24FQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "model = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/Data Augmentation/data/GoogleNews-vectors-negative300.bin.gz\", binary=True)"
      ],
      "metadata": {
        "id": "tB4MDZw6PB5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "3JCdq32BG3vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textaugment"
      ],
      "metadata": {
        "id": "P1plMDKoiKsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textaugment import Wordnet\n",
        "from textaugment import Translate\n",
        "from textaugment import EDA\n",
        "import time\n",
        "count = 0\n",
        "# func = list(map(lambda sentence: EDA().random_insertion(sentence), selected_tweets_1['content']))\n",
        "# print(func)\n",
        "for x, y in enumerate(selected_tweets_1['content']):\n",
        "  selected_tweets_1 = selected_tweets_1.append({'content' : str(EDA().synonym_replacement(y)), 'feeling': str(selected_tweets_1['feeling'][x])}, ignore_index=True)  \n",
        "  selected_tweets_1 = selected_tweets_1.append({'content' : str(EDA().random_deletion(y)), 'feeling': str(selected_tweets_1['feeling'][x])}, ignore_index=True)  \n",
        "  selected_tweets_1 = selected_tweets_1.append({'content' : str(EDA().random_insertion(y)), 'feeling': str(selected_tweets_1['feeling'][x])}, ignore_index=True)  \n",
        "  selected_tweets_1 = selected_tweets_1.append({'content' : str(EDA().random_swap(y)), 'feeling': str(selected_tweets_1['feeling'][x])}, ignore_index=True)  \n",
        "  selected_tweets_1 = selected_tweets_1.append({'content' : str(EDA().synonym_replacement(y)), 'feeling': str(selected_tweets_1['feeling'][x])}, ignore_index=True)\n",
        "  selected_tweets_1 = selected_tweets_1.append({'content' : str(Wordnet(v=True ,n=True, runs=5, p=0.5).augment(y)), 'feeling': str(selected_tweets_1['feeling'][x])}, ignore_index=True) \n",
        "  selected_tweets_1 = selected_tweets_1.append({'content' : str(Wordnet(v=False ,n=True, runs=5, p=0.5).augment(y)), 'feeling': str(selected_tweets_1['feeling'][x])}, ignore_index=True)\n",
        "  selected_tweets_1 = selected_tweets_1.append({'content' : str(Wordnet(v=True ,n=False, runs=5, p=0.5).augment(y)), 'feeling': str(selected_tweets_1['feeling'][x])}, ignore_index=True)\n",
        "  selected_tweets_1 = selected_tweets_1.append({'content' : str(Wordnet(v=True ,n=False, runs=5, p=0.5).augment(y)), 'feeling': str(selected_tweets_1['feeling'][x])}, ignore_index=True)\n",
        "  selected_tweets_1 = selected_tweets_1.append({'content' : str(Translate(src=\"en\", to=\"pt\").augment(y)), 'feeling': str(selected_tweets_1['feeling'][x])}, ignore_index=True) #Românicas\n",
        "  selected_tweets_1 = selected_tweets_1.append({'content' : str(Translate(src=\"en\", to=\"fr\").augment(y)), 'feeling': str(selected_tweets_1['feeling'][x])}, ignore_index=True)\n",
        "  selected_tweets_1 = selected_tweets_1.append({'content' : str(Translate(src=\"en\", to=\"de\").augment(y)), 'feeling': str(selected_tweets_1['feeling'][x])}, ignore_index=True) #Germânicas\n",
        "  selected_tweets_1 = selected_tweets_1.append({'content' : str(Translate(src=\"en\", to=\"da\").augment(y)), 'feeling': str(selected_tweets_1['feeling'][x])}, ignore_index=True)\n",
        "  selected_tweets_1 = selected_tweets_1.append({'content' : str(Translate(src=\"en\", to=\"ja\").augment(y)), 'feeling': str(selected_tweets_1['feeling'][x])}, ignore_index=True) #japonicas\n",
        "  count += 1\n",
        "  if count==19:\n",
        "    break\n",
        "  print('[',count,'/18]')"
      ],
      "metadata": {
        "id": "MYti48UCDT1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa6eff8c-bc68-4812-9bab-c5cd9a6af845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1 /18]\n",
            "[ 2 /18]\n",
            "[ 3 /18]\n",
            "[ 4 /18]\n",
            "[ 5 /18]\n",
            "[ 6 /18]\n",
            "[ 7 /18]\n",
            "[ 8 /18]\n",
            "[ 9 /18]\n",
            "[ 10 /18]\n",
            "[ 11 /18]\n",
            "[ 12 /18]\n",
            "[ 13 /18]\n",
            "[ 14 /18]\n",
            "[ 15 /18]\n",
            "[ 16 /18]\n",
            "[ 17 /18]\n",
            "[ 18 /18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_tweets_1.to_csv('/content/drive/MyDrive/Data Augmentation/data/resultados/results1.csv')"
      ],
      "metadata": {
        "id": "Ed-4N5OUrDiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textaugment import Wordnet #falar sobre falsas sentencas \n",
        "from textaugment import Translate\n",
        "from textaugment import EDA\n",
        "import time\n",
        "count = 0\n",
        "# func = list(map(lambda sentence: EDA().random_insertion(sentence), selected_tweets_2['content']))\n",
        "# print(func)\n",
        "for x, y in enumerate(selected_tweets_2['content']):\n",
        "  selected_tweets_2 = selected_tweets_2.append({'content' : str(EDA().synonym_replacement(y)), 'feeling': str(selected_tweets_2['feeling'][x+18])}, ignore_index=True)  \n",
        "  selected_tweets_2 = selected_tweets_2.append({'content' : str(EDA().random_deletion(y)), 'feeling': str(selected_tweets_2['feeling'][x+18])}, ignore_index=True)  \n",
        "  selected_tweets_2 = selected_tweets_2.append({'content' : str(EDA().random_insertion(y)), 'feeling': str(selected_tweets_2['feeling'][x+18])}, ignore_index=True)  \n",
        "  selected_tweets_2 = selected_tweets_2.append({'content' : str(EDA().random_swap(y)), 'feeling': str(selected_tweets_2['feeling'][x+18])}, ignore_index=True)  \n",
        "  selected_tweets_2 = selected_tweets_2.append({'content' : str(EDA().synonym_replacement(y)), 'feeling': str(selected_tweets_2['feeling'][x+18])}, ignore_index=True)\n",
        "  selected_tweets_2 = selected_tweets_2.append({'content' : str(Wordnet(v=True ,n=True, runs=5, p=0.5).augment(y)), 'feeling': str(selected_tweets_2['feeling'][x+18])}, ignore_index=True) \n",
        "  selected_tweets_2 = selected_tweets_2.append({'content' : str(Wordnet(v=False ,n=True, runs=5, p=0.5).augment(y)), 'feeling': str(selected_tweets_2['feeling'][x+18])}, ignore_index=True)\n",
        "  selected_tweets_2 = selected_tweets_2.append({'content' : str(Wordnet(v=True ,n=False, runs=5, p=0.5).augment(y)), 'feeling': str(selected_tweets_2['feeling'][x+18])}, ignore_index=True)\n",
        "  selected_tweets_2 = selected_tweets_2.append({'content' : str(Wordnet(v=True ,n=False, runs=5, p=0.5).augment(y)), 'feeling': str(selected_tweets_2['feeling'][x+18])}, ignore_index=True)\n",
        "  # selected_tweets_2 = selected_tweets_2.append({'content' : str(Translate(src=\"en\", to=\"ru\").augment(y)), 'feeling': str(selected_tweets_2['feeling'][x+18])}, ignore_index=True) #Românicas\n",
        "  # selected_tweets_2 = selected_tweets_2.append({'content' : str(Translate(src=\"en\", to=\"fr\").augment(y)), 'feeling': str(selected_tweets_2['feeling'][x+18])}, ignore_index=True)\n",
        "  # selected_tweets_2 = selected_tweets_2.append({'content' : str(Translate(src=\"en\", to=\"de\").augment(y)), 'feeling': str(selected_tweets_2['feeling'][x+18])}, ignore_index=True) #Germânicas\n",
        "  # selected_tweets_2 = selected_tweets_2.append({'content' : str(Translate(src=\"en\", to=\"da\").augment(y)), 'feeling': str(selected_tweets_2['feeling'][x+18])}, ignore_index=True)\n",
        "  # selected_tweets_2 = selected_tweets_2.append({'content' : str(Translate(src=\"en\", to=\"ja\").augment(y)), 'feeling': str(selected_tweets_2['feeling'][x+18])}, ignore_index=True) #japonicas\n",
        "  count += 1\n",
        "  if count==19:\n",
        "    break\n",
        "  print('[',count+18,'/36]')"
      ],
      "metadata": {
        "id": "_CzlL5E9FNoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16469db-db35-485f-d048-da5acdbedeb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 19 /36]\n",
            "[ 20 /36]\n",
            "[ 21 /36]\n",
            "[ 22 /36]\n",
            "[ 23 /36]\n",
            "[ 24 /36]\n",
            "[ 25 /36]\n",
            "[ 26 /36]\n",
            "[ 27 /36]\n",
            "[ 28 /36]\n",
            "[ 29 /36]\n",
            "[ 30 /36]\n",
            "[ 31 /36]\n",
            "[ 32 /36]\n",
            "[ 33 /36]\n",
            "[ 34 /36]\n",
            "[ 35 /36]\n",
            "[ 36 /36]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textaugment import Wordnet\n",
        "from textaugment import Translate\n",
        "from textaugment import EDA\n",
        "import time\n",
        "count = 0\n",
        "# func = list(map(lambda sentence: EDA().random_insertion(sentence), selected_tweets_2['content']))\n",
        "# print(func)\n",
        "for x, y in enumerate(selected_tweets_3['content']):\n",
        "  selected_tweets_3 = selected_tweets_3.append({'content' : str(EDA().synonym_replacement(y)), 'feeling': str(selected_tweets_3['feeling'][x])}, ignore_index=True)  \n",
        "  selected_tweets_3 = selected_tweets_3.append({'content' : str(EDA().random_deletion(y)), 'feeling': str(selected_tweets_3['feeling'][x])}, ignore_index=True)  \n",
        "  selected_tweets_3 = selected_tweets_3.append({'content' : str(EDA().random_insertion(y)), 'feeling': str(selected_tweets_3['feeling'][x])}, ignore_index=True)  \n",
        "  selected_tweets_3 = selected_tweets_3.append({'content' : str(EDA().random_swap(y)), 'feeling': str(selected_tweets_3['feeling'][x])}, ignore_index=True)  \n",
        "  selected_tweets_3 = selected_tweets_3.append({'content' : str(EDA().synonym_replacement(y)), 'feeling': str(selected_tweets_3['feeling'][x])}, ignore_index=True)\n",
        "  selected_tweets_3 = selected_tweets_3.append({'content' : str(Wordnet(v=True ,n=True, runs=5, p=0.5).augment(y)), 'feeling': str(selected_tweets_3['feeling'][x])}, ignore_index=True) \n",
        "  selected_tweets_3 = selected_tweets_3.append({'content' : str(Wordnet(v=False ,n=True, runs=5, p=0.5).augment(y)), 'feeling': str(selected_tweets_3['feeling'][x])}, ignore_index=True)\n",
        "  selected_tweets_3 = selected_tweets_3.append({'content' : str(Wordnet(v=True ,n=False, runs=5, p=0.5).augment(y)), 'feeling': str(selected_tweets_3['feeling'][x])}, ignore_index=True)\n",
        "  selected_tweets_3 = selected_tweets_3.append({'content' : str(Wordnet(v=True ,n=False, runs=5, p=0.5).augment(y)), 'feeling': str(selected_tweets_3['feeling'][x])}, ignore_index=True)\n",
        "  # selected_tweets_3 = selected_tweets_3.append({'content' : str(Translate(src=\"en\", to=\"pt\").augment(y)), 'feeling': str(selected_tweets_3['feeling'][x])}, ignore_index=True) #Românicas\n",
        "  # selected_tweets_3 = selected_tweets_3.append({'content' : str(Translate(src=\"en\", to=\"fr\").augment(y)), 'feeling': str(selected_tweets_3['feeling'][x])}, ignore_index=True)\n",
        "  # selected_tweets_3 = selected_tweets_3.append({'content' : str(Translate(src=\"en\", to=\"de\").augment(y)), 'feeling': str(selected_tweets_3['feeling'][x])}, ignore_index=True) #Germânicas\n",
        "  # selected_tweets_3 = selected_tweets_3.append({'content' : str(Translate(src=\"en\", to=\"da\").augment(y)), 'feeling': str(selected_tweets_3['feeling'][x])}, ignore_index=True)\n",
        "  # selected_tweets_3 = selected_tweets_3.append({'content' : str(Translate(src=\"en\", to=\"ja\").augment(y)), 'feeling': str(selected_tweets_3['feeling'][x])}, ignore_index=True) #japonicas\n",
        "  count += 1\n",
        "  if count==19:\n",
        "    break\n",
        "  print('[',count+36,'/50]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjUNinVsnUt-",
        "outputId": "ec835bfe-7bf1-4fd4-f005-aa6e7d608829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 37 /50]\n",
            "[ 38 /50]\n",
            "[ 39 /50]\n",
            "[ 40 /50]\n",
            "[ 41 /50]\n",
            "[ 42 /50]\n",
            "[ 43 /50]\n",
            "[ 44 /50]\n",
            "[ 45 /50]\n",
            "[ 46 /50]\n",
            "[ 47 /50]\n",
            "[ 48 /50]\n",
            "[ 49 /50]\n",
            "[ 50 /50]\n",
            "[ 51 /50]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teste = selected_tweets_3.append(selected_tweets_2)"
      ],
      "metadata": {
        "id": "2QmER_6-trkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = teste.append(selected_tweets_1)"
      ],
      "metadata": {
        "id": "vdWxsNn1t_B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Z8VI3uN4t_wb",
        "outputId": "dd4ba2eb-3446-4949-e00c-317c24b2c5ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                                            content   feeling\n",
              "0          36.0  Is annoyed the queue for the new milkshake pla...  negative\n",
              "1          37.0  i would love to see Ant and Dec doing a dance ...  positive\n",
              "2          38.0                  feeling very lonely..............  negative\n",
              "3          39.0                       which one do you think i am?  positive\n",
              "4          40.0                oh toy story 3 is going to be great  positive\n",
              "..          ...                                                ...       ...\n",
              "265         NaN  i'm just leaving for 2 weeks. and i promise to...  positive\n",
              "266         NaN  i will only have left for 2 weeks. and i promi...  positive\n",
              "267         NaN  i will only be gone for 2 weeks. and i promise...  positive\n",
              "268         NaN  i will only be away for 2 weeks. and i promise...  positive\n",
              "269         NaN  i only disappear for two weeks. and i promise ...  positive\n",
              "\n",
              "[683 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9f86f05-95a7-4fe0-a114-957f4f32f338\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>content</th>\n",
              "      <th>feeling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36.0</td>\n",
              "      <td>Is annoyed the queue for the new milkshake pla...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37.0</td>\n",
              "      <td>i would love to see Ant and Dec doing a dance ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38.0</td>\n",
              "      <td>feeling very lonely..............</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>39.0</td>\n",
              "      <td>which one do you think i am?</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40.0</td>\n",
              "      <td>oh toy story 3 is going to be great</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>NaN</td>\n",
              "      <td>i'm just leaving for 2 weeks. and i promise to...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>NaN</td>\n",
              "      <td>i will only have left for 2 weeks. and i promi...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>NaN</td>\n",
              "      <td>i will only be gone for 2 weeks. and i promise...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>NaN</td>\n",
              "      <td>i will only be away for 2 weeks. and i promise...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>NaN</td>\n",
              "      <td>i only disappear for two weeks. and i promise ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>683 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9f86f05-95a7-4fe0-a114-957f4f32f338')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9f86f05-95a7-4fe0-a114-957f4f32f338 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9f86f05-95a7-4fe0-a114-957f4f32f338');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop([\"Unnamed: 0\"], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "hRIEB6OEuG0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped = df.drop_duplicates(subset=['content'])"
      ],
      "metadata": {
        "id": "d0u8Q6zRvF1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Quantidade de gerações iguais:', len(df)-len(df_dropped))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74UTSOhwvRr6",
        "outputId": "e21e98ec-ffcf-477a-fd62-2e5ecc5b3727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de gerações iguais: 152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#No melhor dos casos de 50 -> 700 sentenças "
      ],
      "metadata": {
        "id": "7xCO-jgYvcGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teste = pd.read_csv('/content/drive/MyDrive/Data Augmentation/data/resultados/results1.csv')"
      ],
      "metadata": {
        "id": "D5Cg8k4jjiWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teste"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1sRdvx6wjlMa",
        "outputId": "4597608a-c755-441e-e43a-fb86b695b270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  Unnamed: 0.1  \\\n",
              "0             0           0.0   \n",
              "1             1           1.0   \n",
              "2             2           2.0   \n",
              "3             3           3.0   \n",
              "4             4           4.0   \n",
              "..          ...           ...   \n",
              "265         265           NaN   \n",
              "266         266           NaN   \n",
              "267         267           NaN   \n",
              "268         268           NaN   \n",
              "269         269           NaN   \n",
              "\n",
              "                                               content   feeling  \n",
              "0    I want to go to Africa to play with MY elephan...  negative  \n",
              "1    hehehe my mom used to get pissed off because i...  positive  \n",
              "2    I actually wanted a daughter too....most dudes...  positive  \n",
              "3                                        HI. back soon  positive  \n",
              "4    my house got cleaned today.. all my stuff got ...  negative  \n",
              "..                                                 ...       ...  \n",
              "265  i'm just leaving for 2 weeks. and i promise to...  positive  \n",
              "266  i will only have left for 2 weeks. and i promi...  positive  \n",
              "267  i will only be gone for 2 weeks. and i promise...  positive  \n",
              "268  i will only be away for 2 weeks. and i promise...  positive  \n",
              "269  i only disappear for two weeks. and i promise ...  positive  \n",
              "\n",
              "[270 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b267f11-cf19-4908-b149-8ae157e54b2c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>content</th>\n",
              "      <th>feeling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I want to go to Africa to play with MY elephan...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>hehehe my mom used to get pissed off because i...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>I actually wanted a daughter too....most dudes...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>HI. back soon</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>my house got cleaned today.. all my stuff got ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>265</td>\n",
              "      <td>NaN</td>\n",
              "      <td>i'm just leaving for 2 weeks. and i promise to...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>266</td>\n",
              "      <td>NaN</td>\n",
              "      <td>i will only have left for 2 weeks. and i promi...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>267</td>\n",
              "      <td>NaN</td>\n",
              "      <td>i will only be gone for 2 weeks. and i promise...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>268</td>\n",
              "      <td>NaN</td>\n",
              "      <td>i will only be away for 2 weeks. and i promise...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>269</td>\n",
              "      <td>NaN</td>\n",
              "      <td>i only disappear for two weeks. and i promise ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>270 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b267f11-cf19-4908-b149-8ae157e54b2c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b267f11-cf19-4908-b149-8ae157e54b2c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b267f11-cf19-4908-b149-8ae157e54b2c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y  in enumerate(teste['content']):\n",
        "  print(x, ':', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u9OAJN-jnHq",
        "outputId": "5d35b6b3-1b37-43dd-c1ef-efd06c84b61e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 : I want to go to Africa to play with MY elephants so badly. In the meantime I guess I'll just watch NEMO!\n",
            "1 : hehehe my mom used to get pissed off because i would sing what's my age again to my grandparents lololol\n",
            "2 : I actually wanted a daughter too....most dudes aint to excited bout having a girl...im on cloud 9 lol\n",
            "3 : HI. back soon\n",
            "4 : my house got cleaned today.. all my stuff got moved around and half of my vicks vapors are gone\n",
            "5 : This mood is more shittysweet then bitter. At least it's FINALLY gettin fixed. UGH.\n",
            "6 : is in college and wants to go home and see her bezzie as she has jus returned from turkey x\n",
            "7 : seriously....that was great stuff....now I am sad\n",
            "8 : I'm on my 600th Tweet!! Woo Hoo!!\n",
            "9 : Yay diversity I think it's quite sad how I got *so* sucked into the program.. haha still, I enjoyed it. And diversity deserved to win!\n",
            "10 : very very little, for money is a little tight this month sadly\n",
            "11 : Mmmmm who doesent lik laying by the pool on a hot day\n",
            "12 : : you always look good baby! yeah, gonna try to have fun...\n",
            "13 : Fell asleep in his jeans last night...\n",
            "14 : FTSK concert May 23?! I'm think Soooo!\n",
            "15 : oh btw, the gway you're following is a fakie. twitter.com/gerardway is the real deal\n",
            "16 : Racheyy just fixed the laptop and is now going home\n",
            "17 : im only going to be gone for 2 weeks. and i promise ill text\n",
            "18 : I want to go to Africa to play with MY elephants so badly. hoosier state the meantime I guess I'll just watch NEMO!\n",
            "19 : I want to go to Africa to play elephants so badly. the meantime I guess I'll NEMO!\n",
            "20 : I want to go to Africa to play with MY elephants so badly. In the meantime I guess get going I'll just watch NEMO!\n",
            "21 : I want to go I'll Africa to play with MY elephants so badly. In the meantime I guess to just watch NEMO!\n",
            "22 : I want to go to Africa to play with MY elephants so badly. hoosier state the meantime I guess I'll just watch NEMO!\n",
            "23 : iodin want to get to africa to diddle with my elephant so badly. in the meantime iodin conjecture i'll just follow nemo!\n",
            "24 : i want to go to africa to play with my elephants so badly. in the meantime iodine guess i'll just watch nemo!\n",
            "25 : i want to depart to africa to diddle with my elephants so badly. in the meantime i guess i'll just observe nemo!\n",
            "26 : i need to get to africa to diddle with my elephants so badly. in the meantime i guess i'll just follow nemo!\n",
            "27 : i want to go to africa to play so much with my elephants. meanwhile, i think i'll just watch nemo!\n",
            "28 : i want to go to africa so much to play with my elephants. in the meantime, i guess i'm just going to watch nemo!\n",
            "29 : i want to go to africa to play with my elephants. in the meantime, i just estimate nemo!\n",
            "30 : i will go to africa to play with my elephants so badly. in the meantime, i assume i just see nemo!\n",
            "31 : i want to go to africa and play very badly with the elephant. until then, i think i just look at nemo!\n",
            "32 : hehehe my mom used to get pissed off because i would let the cat out of the bag what's my age again to my grandparents lololol\n",
            "33 : hehehe my mom used to get pissed off would sing what's age again to my grandparents\n",
            "34 : hehehe my mom used to get pissed off because i would sing what's my age again to my expend grandparents lololol\n",
            "35 : hehehe my mom used grandparents get pissed off because i would sing what's my age again to my to lololol\n",
            "36 : hehehe my mom used to get pissed off because i would let the cat out of the bag what's my age again to my grandparents lololol\n",
            "37 : hehehe my mammy use to commence puddle off because iodine would whistle what's my geezerhood again to my grandparent lololol\n",
            "38 : hehehe my mammy used to get pissed off because ace would sing what's my years again to my grandparents lololol\n",
            "39 : hehehe my mom employ to baffle make off because i would sing what's my age again to my grandparents lololol\n",
            "40 : hehehe my mom expend to commence make off because i would whistle what's my age again to my grandparents lololol\n",
            "41 : hehehe my mother used to be upset because i would sing my age again to my grandparents lololol\n",
            "42 : hehehe my mom used to get angry because i would sing again what my age to my grandparents lololol\n",
            "43 : hehehe my mother got angry because i would sing my grandparents again, which my age is again. lololol lololol\n",
            "44 : hehehe my mom used to be cursed because i would sing what is my age again for my grandparents lololol\n",
            "45 : hehehe my mother was angry because she was angry.\n",
            "46 : I actually wanted a daughter too....most dudes aint to excited bout having a girl...im on cloud ennead lol\n",
            "47 : I actually wanted a daughter too....most dudes aint bout having a on cloud 9 lol\n",
            "48 : I actually desire wanted a daughter too....most dudes aint to excited bout having a girl...im on cloud 9 lol\n",
            "49 : I actually daughter a wanted too....most dudes aint to excited bout having a girl...im on cloud 9 lol\n",
            "50 : I actually wanted a daughter too....most dudes aint to excited bout having a girl...im on cloud ennead lol\n",
            "51 : iodine actually desire a girl too....most dude aint to stir bout consume a girl...im on cloud 9 lol\n",
            "52 : iodine actually wanted a daughter too....most dude aint to excited bout having a girl...im on cloud 9 lol\n",
            "53 : i actually need a daughter too....most dudes aint to agitate bout get a girl...im on cloud 9 lol\n",
            "54 : i actually desire a daughter too....most dudes aint to excite bout consume a girl...im on cloud 9 lol\n",
            "55 : actually, i also wanted a daughter .... most guys are not to cheer up a girl ... i'm in the cloud 9 lol\n",
            "56 : in fact, i also wanted a girl ... most guys are not excited to have a girl ... i am on the cloud 9 lol\n",
            "57 : i actually wanted a daughter ... most guys are not a struggled fight to have a girl ... i'm on cloud 9 lol\n",
            "58 : i actually wanted to have a daughter too .... most dudes aren't into excited bout to have a girl ... im on cloud 9 lol\n",
            "59 : i actually wanted a daughter .... most men are not excited to have a girl ... cloud 9 im lol\n",
            "60 : HI. back before long\n",
            "61 : HI. back soon\n",
            "62 : shortly HI. back soon\n",
            "63 : soon back HI.\n",
            "64 : HI. back before long\n",
            "65 : hi. back soon\n",
            "66 : hi. back soon\n",
            "67 : hi. back soon\n",
            "68 : hi. back soon\n",
            "69 : hey. back soon\n",
            "70 : hello. back soon\n",
            "71 : hello. back soon\n",
            "72 : hello. back soon\n",
            "73 : hello. back soon\n",
            "74 : my house got cleaned today.. all my stuff got locomote around and half of my vicks vapors are gone\n",
            "75 : my house got cleaned today.. all my stuff around and half my vicks vapors are gone\n",
            "76 : my house got cleaned today.. all my stuff got moved around and half of my vicks vapors are houseclean gone\n",
            "77 : my house got cleaned gone all my stuff got moved around and half of my vicks vapors are today..\n",
            "78 : my house got cleaned today.. all my stuff got locomote around and half of my vicks vapors are gone\n",
            "79 : my family baffle houseclean today.. all my hooey commence run around and one-half of my vicks vapours follow depart\n",
            "80 : my house got cleaned today.. all my hooey got moved around and one-half of my vicks vapours are gone\n",
            "81 : my house commence pick today.. all my stuff commence strike around and half of my vicks vapors are depart\n",
            "82 : my house commence houseclean today.. all my stuff commence strike around and half of my vicks vapors follow depart\n",
            "83 : my house was clean today .. all my things moved and half of my vapors of vicks were gone\n",
            "84 : my house was cleaned today. all my things have been moved and half of my vicks vapors left\n",
            "85 : my house was cleaned today. all of my things were moved around and half of my vicks vapors are gone\n",
            "86 : my house was cleaned today .. all my things were moved around and half of my vicks fumes are gone\n",
            "87 : my house has been cleaned today .. everything moves around and half of my vapor is gone\n",
            "88 : This mood is more shittysweet then bitter. At least it's lastly gettin fixed. UGH.\n",
            "89 : This mood is more shittysweet then bitter. At FINALLY gettin fixed.\n",
            "90 : This mood is more climate shittysweet then bitter. At least it's FINALLY gettin fixed. UGH.\n",
            "91 : This mood it's more shittysweet then bitter. At least is FINALLY gettin fixed. UGH.\n",
            "92 : This mood is more shittysweet then bitter. At least it's lastly gettin fixed. UGH.\n",
            "93 : this climate embody more shittysweet then bitter. at least it's finally gettin fixed. ugh.\n",
            "94 : this climate is more shittysweet then bitter. at least it's finally gettin fixed. ugh.\n",
            "95 : this mood follow more shittysweet then bitter. at least it's finally gettin fixed. ugh.\n",
            "96 : this mood follow more shittysweet then bitter. at least it's finally gettin fixed. ugh.\n",
            "97 : this humor is more shittysweet than bitter. at least it is finally being corrected. eca.\n",
            "98 : this mood is more shitty than the bitter. at least, it is finally repaired. ugh.\n",
            "99 : this mood is more shitty than bitter. at least it is finally repaired. pooh.\n",
            "100 : this mood is more shittysweet and then bitter. at least it's finally attached. ugh.\n",
            "101 : this mood is more brilliant than bitter. at least it was finally corrected. hmm.\n",
            "102 : is in college and wants to go home and see her bezzie as she has jus regress from turkey x\n",
            "103 : is in college and wants to go home her bezzie as has jus returned from turkey\n",
            "104 : is in college and wants to go home and see her bezzie as she has jus returned from get going turkey x\n",
            "105 : is in college and turkey to go home and see her bezzie as she has jus returned from wants x\n",
            "106 : is in college and wants to go home and see her bezzie as she has jus regress from turkey x\n",
            "107 : cost in college and desire to last place and fancy her bezzie as she consume jus regress from turkey go\n",
            "108 : is in college and wants to go place and see her bezzie as she has jus returned from bomb ex\n",
            "109 : constitute in college and need to get home and visit her bezzie as she consume jus pass from turkey x\n",
            "110 : follow in college and need to work home and visit her bezzie as she give jus revert from turkey x\n",
            "111 : is in college and wants to go home and see him bezzie when she returned from turkey x\n",
            "112 : is at university and wants to go home and see her bezzie because she came back from turkey x\n",
            "113 : is on college and wants to go home and see her bezzie because she has returned jus from turkey x\n",
            "114 : is in college and will go home and see her bezzie as she has returned from turkey x\n",
            "115 : i was in college, went home and returned from turkish x, so i want to see her bethzi\n",
            "116 : seriously....that was enceinte stuff....now I am sad\n",
            "117 : seriously....that was great stuff....now I am sad\n",
            "118 : seriously....that was great stuff....now expectant I am sad\n",
            "119 : seriously....that I great stuff....now was am sad\n",
            "120 : seriously....that was enceinte stuff....now I am sad\n",
            "121 : seriously....that was great stuff....now ace follow sad\n",
            "122 : seriously....that was great stuff....now ace am sad\n",
            "123 : seriously....that cost great stuff....now i follow sad\n",
            "124 : seriously....that follow great stuff....now i constitute sad\n",
            "125 : seriously .... that was a great thing ... now i'm sad\n",
            "126 : seriously ... it was great ... now i'm sad\n",
            "127 : seriously ... that was great stuff ... now i'm sad\n",
            "128 : seriously .... those were good things .... now i'm sad\n",
            "129 : seriously .... that was wonderful .... i'm sad now\n",
            "130 : I'm on my 600th Tweet!! woo Hoo!!\n",
            "131 : I'm on my 600th Tweet!! Woo Hoo!!\n",
            "132 : I'm on my 600th Tweet!! Woo court Hoo!!\n",
            "133 : I'm Tweet!! my 600th on Woo Hoo!!\n",
            "134 : I'm on my 600th Tweet!! woo Hoo!!\n",
            "135 : i'm on my 600th tweet!! woo hoo!!\n",
            "136 : i'm on my 600th tweet!! woo hoo!!\n",
            "137 : i'm on my 600th tweet!! woo hoo!!\n",
            "138 : i'm on my 600th tweet!! woo hoo!!\n",
            "139 : i'm on my 600th tweet !! woo hoo !!\n",
            "140 : i am on my 600th tweet !! woo hoo !!\n",
            "141 : i'm on my 600th tweet !! woo hoo !!\n",
            "142 : i'm on my 600. tweet !! woo hoo !!\n",
            "143 : i am in my 600th tweet !! ufu !!\n",
            "144 : Yay variety I think it's quite sad how I got *so* sucked into the program.. haha still, I enjoyed it. And variety deserved to win!\n",
            "145 : Yay diversity I think it's quite sad how *so* sucked into program.. haha still, I enjoyed diversity deserved to win!\n",
            "146 : Yay diversity I think it's quite sad how I got *so* sucked into the program.. haha still, I quite an enjoyed it. And diversity deserved to win!\n",
            "147 : Yay diversity I think enjoyed quite sad how I got *so* sucked into the program.. haha still, I it's it. And diversity deserved to win!\n",
            "148 : Yay variety I think it's quite sad how I got *so* sucked into the program.. haha still, I enjoyed it. And variety deserved to win!\n",
            "149 : yay diverseness one remember it's quite sad how i commence *so* nurse into the program.. haha still, iodin relish it. and diverseness merit to win!\n",
            "150 : yay diverseness one think it's quite sad how i got *so* sucked into the program.. haha still, iodin enjoyed it. and diverseness deserved to win!\n",
            "151 : yay diversity i cogitate it's quite sad how i baffle *so* fellate into the program.. haha still, i relish it. and diversity deserve to win!\n",
            "152 : yay diversity i guess it's quite sad how i commence *so* nurse into the program.. haha still, i enjoy it. and diversity merit to win!\n",
            "153 : yay diversity i think it's very sad as i was * so * sucked into the program. haha yet, i liked it. and diversity deserved to win!\n",
            "154 : yay diversity i think it's quite sad to see how i had * so * succi in the program .. haha ​​anyway, i appreciated. and diversity deserved to win!\n",
            "155 : yay variety, i find it pretty sad how i * sucked into the program. haha still, i enjoyed it. and diversity deserves to win!\n",
            "156 : yay diversity i think it's pretty sad how i got * so * sucked into the program .. haha ​​still, i enjoyed it. and diversity deserved to win!\n",
            "157 : yay dinversity i think it's pretty sad how i was sucked into the program. and diversity is worth winning!\n",
            "158 : very very little, for money is a little wet this month sadly\n",
            "159 : very very little, for money is a little month sadly\n",
            "160 : very calendar month very little, for money is a little tight this month sadly\n",
            "161 : very very this for money is a little tight little, month sadly\n",
            "162 : very very little, for money is a little wet this month sadly\n",
            "163 : very very little, for money be a little tight this month sadly\n",
            "164 : very very little, for money is a little tight this month sadly\n",
            "165 : very very little, for money constitute a little tight this month sadly\n",
            "166 : very very little, for money follow a little tight this month sadly\n",
            "167 : very little, for money is a little tight this month, unfortunately\n",
            "168 : very very little, for money is a little tight this month unfortunately\n",
            "169 : very very little, a little scarce for money this month\n",
            "170 : very little for money is unfortunately a little tight this month\n",
            "171 : very small, this month is a little tight for money\n",
            "172 : Mmmmm who doesent lik laying by the pool on a live day\n",
            "173 : Mmmmm who doesent lik laying by the pool hot day\n",
            "174 : Mmmmm consortium who doesent lik laying by the pool on a hot day\n",
            "175 : Mmmmm who a lik laying by the pool on doesent hot day\n",
            "176 : Mmmmm who doesent lik laying by the pool on a live day\n",
            "177 : mmmmm who doesent lik laying by the pool on a hot day\n",
            "178 : mmmmm who doesent lik laying by the pool on a hot day\n",
            "179 : mmmmm who doesent lik laying by the pool on a hot day\n",
            "180 : mmmmm who doesent lik laying by the pool on a hot day\n",
            "181 : mmmmm who likes to lie in the pool on a hot day\n",
            "182 : mmmmm that makes it like lying near the swimming pool with a hot day\n",
            "183 : mmmmm, which lies by the pool on a hot day, to lie on a hot day\n",
            "184 : mmmmm that doesn't like by the pool on a hot day\n",
            "185 : i like to lie by the pool on a hot day\n",
            "186 : : you ever look good baby! yeah, gonna try to have fun...\n",
            "187 : : you always look good baby! yeah, gonna have fun...\n",
            "188 : : you always look good baby! yeah, gonna try await to have fun...\n",
            "189 : : you to look good baby! yeah, gonna try always have fun...\n",
            "190 : : you ever look good baby! yeah, gonna try to have fun...\n",
            "191 : : you always attend good baby! yeah, gonna endeavor to get fun...\n",
            "192 : : you always look good baby! yeah, gonna endeavor to have fun...\n",
            "193 : : you always attend good baby! yeah, gonna try to give fun...\n",
            "194 : : you always look good baby! yeah, gonna try to get fun...\n",
            "195 : : you're always fine, baby! yes, i will try to have fun ...\n",
            "196 : : you always look good baby! yeah, i will try to have fun ...\n",
            "197 : : you always look good, baby! yes, will try to have fun ...\n",
            "198 : : you always look great baby! yeah will try to have fun ...\n",
            "199 : : you always look like a good baby! yeah, i'm going to have fun ...\n",
            "200 : hide asleep in his jeans last night...\n",
            "201 : Fell asleep in his jeans last night...\n",
            "202 : Fell asleep in his at peace jeans last night...\n",
            "203 : Fell jeans in his asleep last night...\n",
            "204 : hide asleep in his jeans last night...\n",
            "205 : pass asleep in his denim last night...\n",
            "206 : fell asleep in his dungaree last night...\n",
            "207 : flow asleep in his jeans last night...\n",
            "208 : pass asleep in his jeans last night...\n",
            "209 : fell asleep in his jeans last night ...\n",
            "210 : fell asleep in his jeans last night ...\n",
            "211 : last night slept in his jeans ...\n",
            "212 : fell asleep in his jeans last night ...\n",
            "213 : i fell asleep last night with his jeans ...\n",
            "214 : FTSK concert May 23?! I'm opine Soooo!\n",
            "215 : FTSK concert May 23?! I'm think Soooo!\n",
            "216 : crataegus laevigata FTSK concert May 23?! I'm think Soooo!\n",
            "217 : FTSK I'm May 23?! concert think Soooo!\n",
            "218 : FTSK concert May 23?! I'm opine Soooo!\n",
            "219 : ftsk concert may 23?! i'm think soooo!\n",
            "220 : ftsk concert may 23?! i'm think soooo!\n",
            "221 : ftsk concert may 23?! i'm think soooo!\n",
            "222 : ftsk concert may 23?! i'm think soooo!\n",
            "223 : ftsk concert may 23?! i think soooo much!\n",
            "224 : ftsk concert may 23?! i think soooo!\n",
            "225 : ftsk concert may 23?! i think soooo!\n",
            "226 : ftsk concert may 23?! i think sooooo!\n",
            "227 : ftsk concert may 23? ! i think it's amazing!\n",
            "228 : oh btw, the gway you're following is a fakie. twitter.com/gerardway is the real heap\n",
            "229 : oh btw, the gway you're following is a is the real\n",
            "230 : oh btw, the gway you're following is a fakie. twitter.com/gerardway is the sight real deal\n",
            "231 : oh btw, twitter.com/gerardway gway you're following is a fakie. the is the real deal\n",
            "232 : oh btw, the gway you're following is a fakie. twitter.com/gerardway is the real heap\n",
            "233 : oh btw, the gway you're watch embody a fakie. twitter.com/gerardway constitute the real sight\n",
            "234 : oh btw, the gway you're following is a fakie. twitter.com/gerardway is the real sight\n",
            "235 : oh btw, the gway you're watch embody a fakie. twitter.com/gerardway follow the real deal\n",
            "236 : oh btw, the gway you're following constitute a fakie. twitter.com/gerardway constitute the real deal\n",
            "237 : ah, btw, the gway you are following is a fakie. twitter.com/gerardway is the real deal\n",
            "238 : oh btw, the drink you follow is a fakie. twitter.com/gerardway is the real deal\n",
            "239 : oh, by the way, the gway, which you follow, is a facie. twitter.com/gerardway is the real business\n",
            "240 : oh btw, gway, you follow, is a fakie. twitter.com/gerardway is the right deal\n",
            "241 : by the way, the gway you are following is fakie. twitter.com/gerardway is real\n",
            "242 : Racheyy just fixed the laptop computer and is now going home\n",
            "243 : Racheyy just fixed the laptop and is now\n",
            "244 : Racheyy just fixed the laptop and is now going touch on home\n",
            "245 : Racheyy just home the laptop and is now going fixed\n",
            "246 : Racheyy just fixed the laptop computer and is now going home\n",
            "247 : racheyy just doctor the laptop and be now depart household\n",
            "248 : racheyy just fixed the laptop and is now going place\n",
            "249 : racheyy just doctor the laptop and follow now get home\n",
            "250 : racheyy just fixate the laptop and follow now get home\n",
            "251 : racheyy has just fixed the laptop and is now going home\n",
            "252 : racheyy has just corrected the laptop and now comes home\n",
            "253 : racheyy has just repaired the laptop and is now going home\n",
            "254 : racheyy just got the laptop and are now going home\n",
            "255 : racheyy has just repaired the laptop and is now home\n",
            "256 : im only going to be gone for two weeks. and i promise ill text\n",
            "257 : im only going to be gone for 2 i promise ill\n",
            "258 : im only going to be gone for 2 weeks. get going and i promise ill text\n",
            "259 : im only and to be gone for 2 weeks. going i promise ill text\n",
            "260 : im only going to be gone for two weeks. and i promise ill text\n",
            "261 : im only depart to constitute depart for 2 weeks. and i hope ailment textbook\n",
            "262 : im only going to be gone for 2 weeks. and i hope ailment text\n",
            "263 : im only depart to constitute depart for 2 weeks. and i promise ill text\n",
            "264 : im only get to constitute get for 2 weeks. and i promise ill text\n",
            "265 : i'm just leaving for 2 weeks. and i promise to send a message\n",
            "266 : i will only have left for 2 weeks. and i promise sick text\n",
            "267 : i will only be gone for 2 weeks. and i promise sick text\n",
            "268 : i will only be away for 2 weeks. and i promise sick text\n",
            "269 : i only disappear for two weeks. and i promise bad text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "thZfNp3TjwZG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}